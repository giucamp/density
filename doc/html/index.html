<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.11"/>
<title>density: overview Overview</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
  $(document).ready(function() { init_search(); });
</script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">density
   </div>
   <div id="projectbrief">C++11 library for paged memory management, function queues, heterogeneous queues and lifo memory management</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.11 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li class="current"><a href="index.html"><span>Main&#160;Page</span></a></li>
      <li><a href="pages.html"><span>Related&#160;Pages</span></a></li>
      <li><a href="namespaces.html"><span>Namespaces</span></a></li>
      <li><a href="annotated.html"><span>Classes</span></a></li>
      <li><a href="files.html"><span>Files</span></a></li>
      <li>
        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <img id="MSearchSelect" src="search/mag_sel.png"
               onmouseover="return searchBox.OnSearchSelectShow()"
               onmouseout="return searchBox.OnSearchSelectHide()"
               alt=""/>
          <input type="text" id="MSearchField" value="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.png" alt=""/></a>
          </span>
        </div>
      </li>
    </ul>
  </div>
</div><!-- top -->
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="headertitle">
<div class="title">overview Overview </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><h2>Density Overview </h2>
<p>Density is a C++ library providing very efficient concurrent heterogeneous queues, non-concurrent stacks, and a page-based memory manager.</p>
<p>Heterogeneous queues can store objects of any type:</p>
<div class="fragment"><div class="line">    <span class="comment">// lock-free queue</span></div><div class="line">    lf_heter_queue&lt;&gt; lf_queue;</div><div class="line">    lf_queue.push(42);</div><div class="line">    lf_queue.emplace&lt;std::complex&lt;double&gt;&gt;(1, 2);</div><div class="line"></div><div class="line">    <span class="keyword">using</span> type = runtime_type&lt;default_type_features, f_ostream&gt;;</div><div class="line"></div><div class="line">    <span class="comment">// non-concurrent queue</span></div><div class="line">    heter_queue&lt;type&gt; queue;</div><div class="line">    queue.push(42);</div><div class="line">    queue.emplace&lt;std::string&gt;(<span class="stringliteral">&quot;abc&quot;</span>);</div><div class="line">    queue.emplace&lt;std::complex&lt;double&gt;&gt;(1.2, 3.4);</div><div class="line"></div><div class="line">    <span class="keywordflow">for</span> (<span class="keyword">const</span> <span class="keyword">auto</span> &amp; val : queue)</div><div class="line">        std::cout &lt;&lt; val &lt;&lt; std::endl;</div></div><!-- fragment --><p> This table shows all the available queues:</p>
<table class="doxtable">
<tr>
<th>concurrency strategy</th><th>function queue</th><th>heterogeneous queue</th><th>Consumers cardinality</th><th>Producers cardinality  </th></tr>
<tr>
<td>single threaded </td><td><a class="el" href="classdensity_1_1function__queue.html">function_queue</a> </td><td><a class="el" href="classdensity_1_1heter__queue.html">heter_queue</a></td><td>- </td><td>- </td></tr>
<tr>
<td>locking </td><td><a class="el" href="classdensity_1_1conc__function__queue.html">conc_function_queue</a> </td><td><a class="el" href="classdensity_1_1conc__heter__queue.html">conc_heter_queue</a></td><td>multiple</td><td>multiple </td></tr>
<tr>
<td>lock-free </td><td><a class="el" href="classdensity_1_1lf__function__queue.html">lf_function_queue</a> </td><td><a class="el" href="classdensity_1_1lf__heter__queue.html">lf_heter_queue</a></td><td>single or multiple</td><td>single or multiple </td></tr>
<tr>
<td>spin-locking </td><td><a class="el" href="classdensity_1_1sp__function__queue.html">sp_function_queue</a> </td><td><a class="el" href="classdensity_1_1sp__heter__queue.html">sp_heter_queue</a></td><td>single or multiple</td><td>single or multiple </td></tr>
</table>
<p>Elements are stored linearly in memory pages, achieving a great memory locality. Furthermore allocating an element most times means just adding the size to allocate to a pointer.</p>
<p>density provides a <a class="el" href="classdensity_1_1lifo__allocator.html">lifo_allocator</a> built upon the page allocator, and a thread-local lifo memory pool (the <em>data-stack</em>), which has roughly the <a class="el" href="lifo_array_benchmarks.html">same performance</a> of the unsafe, C-ish and non-standard <a href="http://man7.org/linux/man-pages/man3/alloca.3.html">alloca</a>. The data stack can only be used indirectly with <a class="el" href="classdensity_1_1lifo__array.html">lifo_array</a> and <a class="el" href="classdensity_1_1lifo__buffer.html">lifo_buffer</a>.</p>
<p>This library is tested against these compilers:</p><ul>
<li>Msc (Visual Studio 2017)</li>
<li>g++-4.9 and g++-7</li>
<li>clang++-4.0 and clang++-5.0</li>
</ul>
<p><a href="https://github.com/giucamp/density">Github Repository</a></p>
<h2><a class="anchor" id="lifo"></a>The data stack </h2>
<p>The data-stack is a thread-local paged memory pool dedicated to <em>lifo</em> allocations. The lifo ordering implies that a thread may reallocate or deallocate only the most recently allocated living block. A violation of this constraint causes undefined behavior. The data stack is actually composed by a set of memory pages and an internal thread-local pointer (the top of the stack). The underlying algorithm is very simple: allocations just add the requested size to the top pointer, and deallocations set the top pointer to the block to deallocate. In case of page switch, the execution jumps to a non-inlined slow path. The data stack has constant initialization, so it doesn't slow down thread creation or require dynamic any initialization guard by the compiler on access. The first time a thread uses the data stack it allocates the first memory page.</p>
<p>The data stack can be accessed only indirectly, with <a class="el" href="classdensity_1_1lifo__array.html">lifo_array</a> and <a class="el" href="classdensity_1_1lifo__buffer.html">lifo_buffer</a>.</p>
<p><code>lifo_array</code> is the easiest and safest way of using the data-stack. A <code>lifo_array</code> is very similar to a raw array, but its size is not a compile time constant. The elements are allocated on the data-stack, rather than on the call-stack, so there is no risk of stack overflow. In case of out of system memory, a <code>std::bad_alloc</code> is thrown.</p>
<div class="fragment"><div class="line">    <span class="keywordtype">void</span> concat_and_print(<span class="keyword">const</span> <span class="keywordtype">char</span> * i_str_1, <span class="keyword">const</span> <span class="keywordtype">char</span> * i_str_2)</div><div class="line">    {</div><div class="line">        <span class="keyword">using namespace </span><a class="code" href="namespacedensity.html">density</a>;</div><div class="line"></div><div class="line">        <span class="keyword">auto</span> <span class="keyword">const</span> len_1 = strlen(i_str_1);</div><div class="line">        <span class="keyword">auto</span> <span class="keyword">const</span> len_2 = strlen(i_str_2);</div><div class="line"></div><div class="line">        <a class="code" href="classdensity_1_1lifo__array.html">lifo_array&lt;char&gt;</a> string(len_1 + len_2 + 1);</div><div class="line">        memcpy(<span class="keywordtype">string</span>.data(), i_str_1, len_1);</div><div class="line">        memcpy(<span class="keywordtype">string</span>.data() + len_1, i_str_2, len_2);</div><div class="line">        <span class="keywordtype">string</span>[len_1 + len_2] = 0;</div><div class="line"></div><div class="line">        std::cout &lt;&lt; <span class="keywordtype">string</span>.data() &lt;&lt; std::endl;</div><div class="line">    }</div></div><!-- fragment --><p> To avoid breaking the lifo constraint and therefore causing the undefined behavior, <code>lifo_array</code>s should be instantiated only in the automatic storage (locally in a function or code block). Following this simple rule there is no way to way to break the lifo constraint.</p>
<p>Actually it is possible instantiating a <code><a class="el" href="classdensity_1_1lifo__array.html">lifo_array</a></code> anywhere, as long as the lifo constraint on the calling thread is not broken. The C++ language is very LIFO friendly, as members of structs and elements of arrays are destroyed in the reverse order they are constructed. Anyway this may be dangerous, so it's not recommended.</p>
<div class="fragment"><div class="line">            <span class="keyword">struct </span>MyStruct</div><div class="line">            {</div><div class="line">                lifo_array&lt;std::string&gt; m_strings{6};</div><div class="line">                lifo_array&lt;std::string&gt; m_other_strings{6};</div><div class="line">            };</div><div class="line"></div><div class="line">            <span class="keyword">struct </span>MyStruct1</div><div class="line">            {</div><div class="line">                lifo_array&lt;MyStruct&gt; m_structs{6};</div><div class="line">                lifo_array&lt;MyStruct&gt; m_other_structs{6};</div><div class="line">            };</div><div class="line"></div><div class="line">            <span class="comment">// In C++ array elements and struct members have lifo-compliant lifetime</span></div><div class="line">            lifo_array&lt;MyStruct&gt; structs{10};</div><div class="line"></div><div class="line">            <span class="comment">// Still legal, but don&#39;t go too far</span></div><div class="line">            lifo_array&lt;std::unique_ptr&lt;MyStruct1&gt;&gt; other_structs{10};</div><div class="line">            std::generate(other_structs.begin(), other_structs.end(), []() {</div><div class="line">                <span class="keywordflow">return</span> std::unique_ptr&lt;MyStruct1&gt;(<span class="keyword">new</span> MyStruct1);</div><div class="line">            });</div></div><!-- fragment --><p> Just like built-in arrays and <code>std::array</code>, <code>lifo_array</code> does not initialize elements if they have <a href="https://stackoverflow.com/questions/146452/what-are-pod-types-in-c">POD type</a>, unless an explicit initialization value is provided to the constructor. This is a big difference with <code>std::vector</code>.</p>
<p>A <code><a class="el" href="classdensity_1_1lifo__buffer.html">lifo_buffer</a></code> allocates on the data stack an untyped raw memory block with dynamic size. Unlike <code>lifo_array</code> it supports resizing, but only on the most recently instantiated living instance, and only if a more recent living <code>lifo_array</code> doesn't exist. If the resize changes the address of the block, the surviving content is preserved <code>memcpy</code>'ing it.</p>
<div class="fragment"><div class="line">    <span class="keywordtype">void</span> func(<span class="keywordtype">size_t</span> i_size)</div><div class="line">    {</div><div class="line">        <span class="keyword">using namespace </span><a class="code" href="namespacedensity.html">density</a>;</div><div class="line"></div><div class="line">        <a class="code" href="classdensity_1_1lifo__buffer.html">lifo_buffer</a> buffer_1(i_size);</div><div class="line">        assert(buffer_1.size() == i_size);</div><div class="line"></div><div class="line">        <a class="code" href="classdensity_1_1lifo__buffer.html">lifo_buffer</a> buffer_2; <span class="comment">// now buffer_1 can&#39;t be resized until buffer_2 is destroyed</span></div><div class="line">        assert(buffer_2.size() == 0);</div><div class="line"></div><div class="line">        <span class="keyword">auto</span> mem = buffer_2.<a class="code" href="classdensity_1_1lifo__buffer.html#a6a8503ab246153dde663abc4577a8421">resize</a>(<span class="keyword">sizeof</span>(<span class="keywordtype">int</span>));</div><div class="line">        assert(mem == buffer_2.data());</div><div class="line">        *<span class="keyword">static_cast&lt;</span><span class="keywordtype">int</span> *<span class="keyword">&gt;</span>(mem) = 5;</div><div class="line"></div><div class="line">        mem = buffer_2.resize(<span class="keyword">sizeof</span>(<span class="keywordtype">int</span>) * 20);</div><div class="line">        assert(*static_cast&lt;int *&gt;(mem) == 5);</div><div class="line"></div><div class="line">        <a class="code" href="classdensity_1_1lifo__array.html">lifo_array&lt;int&gt;</a> other_numbers(7);</div><div class="line">        <span class="comment">// buffer_2.resize(20); &lt;---- violation of the lifo constraint, other_numbers is more recent!</span></div><div class="line">    }</div></div><!-- fragment --><p> Internally the data stack is a thread-local instance of <a class="el" href="classdensity_1_1lifo__allocator.html">lifo_allocator</a>, a class template that provides lifo memory management. This class can be used to exploit performances of lifo memory in other contexts, but it is a low-level class: it should be wrapped in some data structure, rather than used directly.</p>
<h2><a class="anchor" id="queues"></a>About function queues </h2>
<p>A function queue is an heterogeneous FIFO pseudo-container that stores callable objects, each with a different type, but all invokable with the same signature. Fundamentally a function queue is a queue of <code>std::function</code>-like objects that uses an in-page linear allocation for the storage of the captures.</p>
<div class="fragment"><div class="line">            <span class="comment">// put a lambda</span></div><div class="line">            function_queue&lt;void()&gt; queue;</div><div class="line">            queue.push([] { std::cout &lt;&lt; <span class="stringliteral">&quot;Printing...&quot;</span> &lt;&lt; std::endl; });</div><div class="line"></div><div class="line">            <span class="comment">// we can have a capture of any size</span></div><div class="line">            <span class="keywordtype">double</span> pi = 3.1415;</div><div class="line">            queue.push([pi] { std::cout &lt;&lt; pi &lt;&lt; std::endl; });</div><div class="line"></div><div class="line">            <span class="comment">// now we execute the functions</span></div><div class="line">            <span class="keywordtype">int</span> executed = 0;</div><div class="line">            <span class="keywordflow">while</span> (queue.try_consume())</div><div class="line">                executed++;</div></div><!-- fragment --><p> If the return type of the signature is <code>void</code>, the function <code>try_consume</code> returns a boolean indicating whether a function has been called. Otherwise it returns an <code>optional</code> containing the return value of the function, or empty if no function was present. Any callable object can be pushed on the queue: a lambda, the result of an <code>std::bind</code>, a (possibly local) class defining an operator (), a pointer to member function or variable. The actual signature of the callable does not need to match the one of the queue, as long as an implicit conversion exists:</p>
<div class="fragment"><div class="line">            function_queue&lt;std::string(const char * i_prefix)&gt; queue;</div><div class="line">            queue.push([](std::string i_prefix) { <span class="keywordflow">return</span> i_prefix + <span class="stringliteral">&quot;...&quot;</span>; });</div></div><!-- fragment --><p> All queues in density have a very simple implementation: a <em>tail pointer</em>, an <em>head pointer</em>, and a set of memory pages. Paging is a kind of quantization of memory: all pages have a fixed size (by default slightly less than 64 kibibyte) and a fixed alignment (by default 64 kibibyte), so that the allocator can be simple and efficient. Values are arranged in the queue by <em>linear allocation</em>: allocating a value means just adding its size to the tail pointer. If the new tail pointer would point outside the last page, a new page is allocated, and the linear allocation is performed from there. In case of very huge values, only a pointer is allocated in the pages, and the actual storage for the value is allocated in the heap.</p>
<h2>Transactional puts and raw allocations </h2>
<p>The functions <code><a class="el" href="classdensity_1_1function__queue.html#ab16cc74a3c5e9d1f9bf798029df5274a">function_queue::push</a></code> and <code><a class="el" href="classdensity_1_1function__queue.html#a49d0820906b9bd4c1b5a1b08980a9330">function_queue::emplace</a></code> append a callable at the end of the queue. This is the quick way of doing a <em>put transaction</em>. We can have more control breaking it using the <b>start_</b> put functions:</p>
<div class="fragment"><div class="line">            <span class="keyword">struct </span>Message</div><div class="line">            {</div><div class="line">                <span class="keyword">const</span> <span class="keywordtype">char</span> * m_text;</div><div class="line"></div><div class="line">                <span class="keywordtype">void</span> operator()() { std::cout &lt;&lt; m_text &lt;&lt; std::endl; }</div><div class="line">            };</div><div class="line"></div><div class="line">            function_queue&lt;void()&gt; queue;</div><div class="line"></div><div class="line">            <span class="keyword">auto</span> transaction             = queue.start_emplace&lt;Message&gt;();</div><div class="line">            transaction.element().m_text = transaction.raw_allocate_copy(<span class="stringliteral">&quot;Hello world&quot;</span>);</div><div class="line">            transaction.commit();</div><div class="line"></div><div class="line">            <span class="keywordtype">bool</span> <span class="keyword">const</span> invoked = queue.try_consume();</div><div class="line">            assert(invoked);</div></div><!-- fragment --><p> The start_* put functions return a <a href="classdensity_1_1heter__queue_1_1put__transaction.html">put_transaction</a> by which the caller can:</p>
<ul>
<li>access the object being pushed before it becomes observable</li>
<li><a href="classdensity_1_1heter__queue_1_1put__transaction.html#a96491d550e91a5918050bfdafe43a72c">commit</a> the transaction so that the element becomes observable to consumers (the <code>put_transaction</code> becomes empty).</li>
<li><a href="classdensity_1_1heter__queue_1_1put__transaction.html#a209a4e37e25451c144910d6f6aa4911e">cancel</a> the transaction, in which case the transaction is discarded with no observable side effects (the <code>put_transaction</code> becomes empty).</li>
<li>allocate <em>raw memory blocks</em>, that is uninitialized memory, or arrays of a trivially destructible type (<code>char</code>s, <code>float</code>s) that are linearly allocated in the pages, right after the last allocated value. There is no function to deallocate raw blocks: they are automatically deallocated after the associated element has been canceled or consumed.</li>
</ul>
<p>When a non-empty <code>put_transaction</code> is destroyed, the bound transaction is canceled. As a consequence, if the <code>raw_allocate_copy</code> in the code above throws an exception, the transaction is discarded with no side effects.</p>
<p>Raw memory blocks are handled in the same way of canceled and consumed values (they are referred as <em>dead</em> values). Internally the storage of dead values is deallocated when the whole page is returned to the page allocator, but this is an implementation detail. When a consume is committed, the head pointer is advanced, skipping any dead element.</p>
<p>Internally instant puts are implemented in terms of transactional puts, so there is no performance difference between them:</p>
<p><code> ... = omissis<br />
 template &lt;...&gt; void emplace(...)<br />
 {<br />
 start_emplace(...).commit();<br />
 }<br />
</code></p>
<p>Consume operations have the <code>start_*</code> variant in heterogeneous queues (but not in function queues). Anyway this operation is not a transaction, as the element disappears from the queue when the operation starts, and will reappear if the operation is canceled.</p>
<h2>Reentrancy </h2>
<p>During a put or a consume operation an heterogeneous or function queue is not in a consistent state <em>for the caller thread</em>. So accessing the queue in any way, in the between of a start_* function and the cancel/commit, causes undefined behavior. Anyway, especially for consumers, reentrancy is sometimes necessary: a callable object, during the invocation, may need to push another callable object to the same queue. For every put or consume function, in every queue, there is a reentrant variant.</p>
<div class="fragment"><div class="line">                conc_function_queue&lt;void(), default_allocator, ERASURE&gt; queue;</div><div class="line"></div><div class="line">                <span class="keyword">auto</span> func1 = [&amp;queue] {</div><div class="line">                    std::cout &lt;&lt; (queue.empty() ? <span class="stringliteral">&quot;The queue is empty&quot;</span> : <span class="stringliteral">&quot;The queue is not empty&quot;</span>)</div><div class="line">                              &lt;&lt; std::endl;</div><div class="line">                };</div><div class="line"></div><div class="line">                <span class="keyword">auto</span> func2 = [&amp;queue, func1] { queue.push(func1); };</div><div class="line"></div><div class="line">                queue.push(func1);</div><div class="line">                queue.push(func2);</div><div class="line"></div><div class="line">                <span class="comment">/* The callable objects we are going to invoke will access the queue, so we</span></div><div class="line"><span class="comment">                    must use a reentrant consume. Note: during the invoke of the last function</span></div><div class="line"><span class="comment">                    the queue is empty to any observer. */</span></div><div class="line">                <span class="keywordflow">while</span> (queue.try_reentrant_consume())</div><div class="line">                    ;</div><div class="line"></div><div class="line">                <span class="comment">// Output:</span></div><div class="line">                <span class="comment">// The queue is not empty</span></div><div class="line">                <span class="comment">// The queue is empty</span></div></div><!-- fragment --><p> If an operation is not reentrant the implementation can do some optimizations: single-thread queues start puts in the committed state, so that the commit is a no-operation. Furthermore reentrancy can affect thread synchronization: <code><a class="el" href="classdensity_1_1conc__function__queue.html">conc_function_queue</a></code> and <code><a class="el" href="classdensity_1_1conc__heter__queue.html">conc_heter_queue</a></code>, when executing a non-reentrant operation, lock their internal mutex when starting, and unlock it when committing or canceling. In contrast, when they execute a reentrant operation, they have to lock and unlock when starting, and lock and unlock again when committing or canceling. The internal mutex is not recursive, so if a thread starts a non-reentrant operation and then tries to access the queue, it causes undefined behavior.</p>
<h2>Relaxed guarantees </h2>
<p>Function queues use type erasure to handle callable objects of heterogeneous types. By default two operations are captured for each element type: invoke-destroy, and just-destroy. The third template parameter of all function queues is an enum of type <a href="namespacedensity.html#a80100b808e35e98df3ffe74cc2293309">function_type_erasure</a> that controls the type erasure: the value function_manual_clear excludes the second operation, so that the function queue will not be able to destroy a callable without invoking it. This gives a performance benefit, at the price that the queue can't be cleared, and that the user must ensure that the queue is empty when destroyed. Internally, in manual-clean mode, the layout of a value in the function queue is composed by:</p>
<ul>
<li>an overhead pointer (that points to the next value, and keeps the state of the value in the least significant bits)</li>
<li>the runtime type, actually a pointer to the invoke-destroy function</li>
<li>the eventual capture</li>
</ul>
<p>So if you put a capture-less lambda or a pointer to a function, you are advancing the tail pointer by the space required by 2 pointers. Anyway lock-free queues and spin-locking queues align their values to <a href="namespacedensity.html#ae8f72b2dd386b61bf0bc4f30478c2941">density::destructive_interference_size</a>, so they are less dense than the other queues.</p>
<p>All queues but <code><a class="el" href="classdensity_1_1function__queue.html">function_queue</a></code> and <code><a class="el" href="classdensity_1_1heter__queue.html">heter_queue</a></code> are concurrency enabled. By default they allow multiple producers and multiple consumers. The class templates <a href="classdensity_1_1lf__function__queue.html">lf_function_queue</a>, <a href="classdensity_1_1lf__heter__queue.html">lf_hetr_queue</a>, <a href="classdensity_1_1sp__function__queue.html">sp_function_queue</a> and <a href="classdensity_1_1sp__heter__queue.html">sp_hetr_queue</a> allow to specify, with 2 independent template arguments of type <a href="namespacedensity.html#aeef74ec0c9bea0ed2bc9802697c062cb">concurrency_cardinality</a>, whether multiple threads are allowed to produce, and whether multiple threads are allowed to consume:</p>
<div class="fragment"><div class="line">            <span class="comment">// single producer, multiple consumers:</span></div><div class="line">            <span class="keyword">using</span> Lf_SpMc_FuncQueue = lf_function_queue&lt;</div><div class="line">              void(),</div><div class="line">              <a class="code" href="namespacedensity.html#adeb11d97131a6de72c7b1d4b6c10f342">default_allocator</a>,</div><div class="line">              <a class="code" href="namespacedensity.html#a80100b808e35e98df3ffe74cc2293309a76acf7643b092fa57f647e10bc2a9cb7">function_standard_erasure</a>,</div><div class="line">              <a class="code" href="namespacedensity.html#aeef74ec0c9bea0ed2bc9802697c062cbae1ce2a7473bbc1bd591b972e7e20a216">concurrency_single</a>,</div><div class="line">              <a class="code" href="namespacedensity.html#aeef74ec0c9bea0ed2bc9802697c062cba88621d57c38a770975b5e262d557c06b">concurrency_multiple</a>&gt;;</div><div class="line"></div><div class="line">            <span class="comment">// multiple consumers, single producer:</span></div><div class="line">            <span class="keyword">using</span> Lf_MpSc_FuncQueue = lf_function_queue&lt;</div><div class="line">              void(),</div><div class="line">              <a class="code" href="namespacedensity.html#adeb11d97131a6de72c7b1d4b6c10f342">default_allocator</a>,</div><div class="line">              <a class="code" href="namespacedensity.html#a80100b808e35e98df3ffe74cc2293309a76acf7643b092fa57f647e10bc2a9cb7">function_standard_erasure</a>,</div><div class="line">              <a class="code" href="namespacedensity.html#aeef74ec0c9bea0ed2bc9802697c062cba88621d57c38a770975b5e262d557c06b">concurrency_multiple</a>,</div><div class="line">              concurrency_single&gt;;</div><div class="line"></div><div class="line">            <span class="comment">// multiple producer, multiple consumers (the default):</span></div><div class="line">            <span class="keyword">using</span> Lf_MpMc_FuncQueue = lf_function_queue&lt;void()&gt;;</div></div><!-- fragment --><p> When dealing with a multiple producers, the tail pointer is an atomic variable. Otherwise it is a plain variable. When dealing with a multiple consumers, the head pointer is an atomic variable. Otherwise it is a plain variable.</p>
<p>The class templates <a href="classdensity_1_1lf__function__queue.html">lf_function_queue</a> and <a href="classdensity_1_1lf__heter__queue.html">lf_hetr_queue</a> allow a further optimization with a template argument of type <a href="namespacedensity.html#ad5d59321f5f1b9a040c6eb9bc500a051">consistency_model</a>: by default the queue is sequential consistent (that is all threads observe the operations happening in the same order). If <a class="el" href="namespacedensity.html#ad5d59321f5f1b9a040c6eb9bc500a051a015795db2a00da5b4aac9f2061908c08">consistency_relaxed</a> is specified, this guarantee is removed, with a great performance benefit.</p>
<p>For all queues, the functions <code>try_consume</code> and <code>try_reentrant_consume</code> have 2 variants:</p>
<ul>
<li>one returning a consume operation. If the queue was empty, an empty consume is returned.</li>
<li>one taking a reference to a consume as parameter and returning a boolean, recommended if a thread performs many consecutive consumes.</li>
</ul>
<p>There is no functional difference between the two consumes. Anyway, currently only for lock-free and spin-locking queues supporting multi-producers, the second consume can be much faster. The reason has to do with the way they ensure that a consumer does not deallocate a page while another consumer is reading it. When a consumer needs to access a page, it increments a ref-count in the page (it <em>pins</em> the page), to notify to the allocator that it is using it. When it has finished, the consumer decrements the ref-count (it <em>unpins</em> the page). If a thread performs many consecutive consumes, it will ends up doing many atomic increments and decrements of the same page (which is a somewhat expensive operation). Since the pin logic is encapsulated in the <code>consume_operation</code>, if the consumer thread keeps the <code>consume_operation</code> alive, pinning and unpinning will be performed only in case of page switch. Note: a forgotten <code>consume_operation</code> which has pinned a page prevents the page from being recycled by the page allocator, even if it was deallocated by another consumer.</p>
<h2>Heterogeneous queues </h2>
<p>Every function queue is actually an adaptor for the corresponding heterogeneous pseudo-container. Heterogeneous queues have put and consume functions, just like function queues, but elements are not required to be callable objects.</p>
<div class="fragment"><div class="line">            heter_queue&lt;&gt; queue;</div><div class="line">            queue.push(19);                     <span class="comment">// the parameter can be an l-value or an r-value</span></div><div class="line">            queue.emplace&lt;std::string&gt;(8, <span class="charliteral">&#39;*&#39;</span>); <span class="comment">// pushes &quot;********&quot;</span></div></div><!-- fragment --><p> The first 3 template parameters are the same for all the heterogeneous queues.</p>
<table class="doxtable">
<tr>
<th>Template parameter </th><th>Meaning </th><th>Constraints</th><th>Default  </th></tr>
<tr>
<td>typename <code>COMMON_TYPE</code></td><td>Common type of elements</td><td>Must decay to itself (see <a href="http://en.cppreference.com/w/cpp/types/decay">std::decay</a>)</td><td><code>void</code> </td></tr>
<tr>
<td>typename <code>RUNTIME_TYPE</code></td><td>Type eraser type</td><td>Must model <a href="RuntimeType_requirements.html">RuntimeType</a></td><td><a href="classdensity_1_1runtime__type.html">runtime_type</a> </td></tr>
<tr>
<td>typename <code>ALLOCATOR_TYPE</code></td><td>Allocator</td><td>Must model both <a href="PagedAllocator_requirements.html">PageAllocator</a> and <a href="UntypedAllocator_requirements.html">UntypedAllocator</a></td><td><a href="namespacedensity.html#a06c6ce21f0d3cede79e2b503a90b731e">default_allocator</a> </td></tr>
</table>
<p>An element can be pushed on a queue if its address is is implicitly convertible to <code>COMMON_TYPE*</code>. By default any type is allowed in the queue. The <code>RUNTIME_TYPE</code> type allows much more customization than the <a href="namespacedensity.html#a80100b808e35e98df3ffe74cc2293309">function_type_erasure</a> template parameter of function queues. Even using the built-in <a href="classdensity_1_1runtime__type.html">runtime_type</a> you can select which operations the elements of the queue should support, and add your own.</p>
<div class="fragment"><div class="line"></div><div class="line">    <span class="comment">/* This feature calls an update function on any object. The update has not to be virtual, as</span></div><div class="line"><span class="comment">        type erasure already is a kind of virtualization. */</span></div><div class="line">    <span class="keyword">struct </span>feature_call_update</div><div class="line">    {</div><div class="line">        void (*m_func)(<span class="keywordtype">void</span> * i_object, <span class="keywordtype">float</span> i_elapsed_time);</div><div class="line"></div><div class="line">        <span class="keywordtype">void</span> operator()(<span class="keywordtype">void</span> * i_object, <span class="keywordtype">float</span> i_elapsed_time)<span class="keyword"> const</span></div><div class="line"><span class="keyword">        </span>{</div><div class="line">            m_func(i_object, i_elapsed_time);</div><div class="line">        }</div><div class="line"></div><div class="line">        <span class="keyword">template</span> &lt;<span class="keyword">typename</span> TARGET_TYPE&gt; constexpr <span class="keyword">static</span> feature_call_update make() noexcept</div><div class="line">        {</div><div class="line">            <span class="keywordflow">return</span> feature_call_update{&amp;invoke&lt;TARGET_TYPE&gt;};</div><div class="line">        }</div><div class="line"></div><div class="line">      <span class="keyword">private</span>:</div><div class="line">        <span class="keyword">template</span> &lt;<span class="keyword">typename</span> TARGET_TYPE&gt;</div><div class="line">        <span class="keyword">static</span> <span class="keywordtype">void</span> invoke(<span class="keywordtype">void</span> * i_object, <span class="keywordtype">float</span> i_elapsed_time) noexcept</div><div class="line">        {</div><div class="line">            <span class="keyword">static_cast&lt;</span>TARGET_TYPE *<span class="keyword">&gt;</span>(i_object)-&gt;update(i_elapsed_time);</div><div class="line">        }</div><div class="line">    };</div></div><!-- fragment --><div class="fragment"><div class="line"></div><div class="line">            <span class="keyword">struct </span>ObjectA</div><div class="line">            {</div><div class="line">                <span class="keywordtype">void</span> update(<span class="keywordtype">float</span> i_elapsed_time)</div><div class="line">                {</div><div class="line">                    std::cout &lt;&lt; <span class="stringliteral">&quot;ObjectA::update(&quot;</span> &lt;&lt; i_elapsed_time &lt;&lt; <span class="stringliteral">&quot;)&quot;</span> &lt;&lt; std::endl;</div><div class="line">                }</div><div class="line">            };</div><div class="line"></div><div class="line">            <span class="keyword">struct </span>ObjectB</div><div class="line">            {</div><div class="line">                <span class="keywordtype">void</span> update(<span class="keywordtype">float</span> i_elapsed_time)</div><div class="line">                {</div><div class="line">                    std::cout &lt;&lt; <span class="stringliteral">&quot;ObjectB::update(&quot;</span> &lt;&lt; i_elapsed_time &lt;&lt; <span class="stringliteral">&quot;)&quot;</span> &lt;&lt; std::endl;</div><div class="line">                }</div><div class="line">            };</div><div class="line"></div><div class="line">            <span class="comment">// concatenates feature_call_update to the default features (f_destroy, f_size, f_alignment)</span></div><div class="line">            <span class="keyword">using</span> MyFeatures = feature_list&lt;default_type_features, feature_call_update&gt;;</div><div class="line"></div><div class="line">            <span class="comment">// create a queue with 3 objects</span></div><div class="line">            heter_queue&lt;runtime_type&lt;MyFeatures&gt;, default_allocator&gt; my_queue;</div><div class="line">            my_queue.emplace&lt;ObjectA&gt;();</div><div class="line">            my_queue.emplace&lt;ObjectB&gt;();</div><div class="line">            my_queue.emplace&lt;ObjectB&gt;();</div><div class="line"></div><div class="line">            <span class="comment">// call update on all the objects</span></div><div class="line">            <span class="keyword">auto</span> <span class="keyword">const</span> end_it = my_queue.end();</div><div class="line">            <span class="keywordflow">for</span> (<span class="keyword">auto</span> it = my_queue.begin(); it != end_it; ++it)</div><div class="line">            {</div><div class="line">                <span class="keyword">auto</span> <span class="keyword">const</span> update_func = it-&gt;type().get_feature&lt;feature_call_update&gt;();</div><div class="line">                update_func(it-&gt;address(), 1.f / 60.f);</div><div class="line">            }</div></div><!-- fragment --><p> Output:</p>
<div class="fragment"><div class="line">ObjectA::update(0.0166667)</div><div class="line">ObjectB::update(0.0166667)</div><div class="line">ObjectB::update(0.0166667)</div></div><!-- fragment --><h2>Implementation details </h2>
<p><a href="implementation.pdf" target="_blank">This document</a> describes some of the internals of density.</p>
<h2>Named requirements </h2>
<p><a href="RuntimeType_requirements.html">RuntimeType</a> | <a href="classdensity_1_1runtime__type.html">runtime_type</a> <a href="TypeFeature_requirements.html">TypeFeature</a> | <a class="el" href="classdensity_1_1f__size.html">f_size</a>, <a class="el" href="classdensity_1_1f__alignment.html">f_alignment</a>, <a class="el" href="classdensity_1_1f__copy__construct.html">f_copy_construct</a>, <a class="el" href="classdensity_1_1f__hash.html">f_hash</a>, <a class="el" href="classdensity_1_1f__rtti.html">f_rtti</a> <a href="UntypedAllocator_requirements.html">UntypedAllocator</a> | <a href="namespacedensity.html#a06c6ce21f0d3cede79e2b503a90b731e">default_allocator</a>, <a href="classdensity_1_1basic__void__allocator.html">basic_default_allocator</a> <a href="PagedAllocator_requirements.html">PagedAllocator</a> | <a href="namespacedensity.html#a06c6ce21f0d3cede79e2b503a90b731e">default_allocator</a>, <a href="classdensity_1_1basic__void__allocator.html">basic_default_allocator</a></p>
<h2>Benchmarks </h2>
<p><a class="el" href="function_queue_benchmarks.html">function_queue_benchmarks</a></p>
<p><a class="el" href="lifo_array_benchmarks.html">lifo_array_benchmarks</a> </p>
</div></div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.11
</small></address>
</body>
</html>
